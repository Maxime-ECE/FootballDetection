{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 images et leurs annotations sélectionnées et copiées vers C:/Users/YANISOUUUUUUUUGERARD/Desktop/opencv_train/to_import\\images et C:/Users/YANISOUUUUUUUUGERARD/Desktop/opencv_train/to_import\\labels.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Chemin vers le dossier du dataset\n",
    "dataset_path = 'test'  # Remplacez par le chemin de votre dataset\n",
    "# Chemin vers le dossier de sortie\n",
    "output_path = 'a_importer'  # Dossier de sortie\n",
    "\n",
    "# Dossiers sources\n",
    "images_source_dir = os.path.join(dataset_path, 'images')       # Dossier source pour les images\n",
    "labels_source_dir = os.path.join(dataset_path, 'labels')   # Dossier source pour les annotations\n",
    "\n",
    "# Dossiers de sortie pour les images et les annotations\n",
    "images_output_dir = os.path.join(output_path, 'images')         # Dossier pour les images\n",
    "labels_output_dir = os.path.join(output_path, 'labels')     # Dossier pour les annotations\n",
    "\n",
    "# Créer les dossiers de sortie s'ils n'existent pas\n",
    "os.makedirs(images_output_dir, exist_ok=True)\n",
    "os.makedirs(labels_output_dir, exist_ok=True)\n",
    "\n",
    "# Lister toutes les images dans le dossier source des images\n",
    "all_images = [f for f in os.listdir(images_source_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]  # Ajouter d'autres formats si nécessaire\n",
    "\n",
    "# Calculer le nombre d'images à sélectionner (10 %)\n",
    "num_images_to_select = max(1, 50)  # Au moins 1 image si le dataset est très petit\n",
    "\n",
    "# Sélectionner aléatoirement 10 % des images\n",
    "selected_images = random.sample(all_images, num_images_to_select)\n",
    "\n",
    "# Copier les images et leurs fichiers d'annotation correspondants dans les dossiers de sortie\n",
    "for image in selected_images:\n",
    "    # Copier l'image\n",
    "    shutil.copy(os.path.join(images_source_dir, image), os.path.join(images_output_dir, image))\n",
    "\n",
    "    # Copier le fichier d'annotation correspondant\n",
    "    label_file = os.path.splitext(image)[0] + '.txt'  # Remplace l'extension de l'image par .txt\n",
    "    if os.path.exists(os.path.join(labels_source_dir, label_file)):  # Vérifie si le fichier d'annotation existe\n",
    "        shutil.copy(os.path.join(labels_source_dir, label_file), os.path.join(labels_output_dir, label_file))\n",
    "\n",
    "print(f\"{num_images_to_select} images et leurs annotations sélectionnées et copiées vers {images_output_dir} et {labels_output_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger le modèle\n",
    "model = YOLO('lien_best.pt')\n",
    "# Charger la vidéo\n",
    "video_path = 'video_entré'\n",
    "output_path = 'video_sortie'\n",
    "save_dir = '../buts'  # Nouveau dossier pour les buts\n",
    "\n",
    "# Créer le dossier s'il n'existe pas\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Paramètres pour l'enregistrement de la vidéo de sortie\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec vidéo\n",
    "out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "def est_but(cage_coords, ballon_coords):\n",
    "    cx_min, cy_min, cx_max, cy_max = cage_coords\n",
    "    bx_min, by_min, bx_max, by_max = ballon_coords\n",
    "    print(f\"Vérification du but : Cage ({cx_min}, {cy_min}, {cx_max}, {cy_max}), Ballon ({bx_min}, {by_min}, {bx_max}, {by_max})\")\n",
    "\n",
    "    if bx_min > cx_min and bx_max < cx_max and by_min > cy_min and by_max < cy_max:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "frame_count = 0  # Compteur de frames pour le nom des fichiers\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Appliquer le modèle YOLO sur chaque frame\n",
    "    results = model.predict(source=frame)\n",
    "\n",
    "    # Initialisation des coordonnées de la cage et du ballon\n",
    "    cage_coords = None\n",
    "    ballon_coords = None\n",
    "\n",
    "    # Extraction des coordonnées de chaque détection\n",
    "    for detection in results[0].boxes:\n",
    "        classe = int(detection.cls)  # ID de classe sous forme d'entier\n",
    "        class_name = model.names[classe]  # Obtenir le nom de la classe\n",
    "        x_min, y_min, x_max, y_max = map(int, detection.xyxy[0])  # Coordonnées de la boîte\n",
    "\n",
    "        print(f\"Classe: {class_name}, Coordonnées: ({x_min}, {y_min}, {x_max}, {y_max})\")\n",
    "\n",
    "        if class_name == 'cage':\n",
    "            cage_coords = (x_min, y_min, x_max, y_max)\n",
    "        elif class_name == 'ball':  # Utiliser \"ball\" au lieu de \"ballon\"\n",
    "            ballon_coords = (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    # Vérifier s'il y a but\n",
    "    if cage_coords and ballon_coords:\n",
    "        if est_but(cage_coords, ballon_coords):\n",
    "            print(\"But détecté !\")\n",
    "            cv2.putText(frame, \"But détecté !\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            # Sauvegarder l'image de but\n",
    "            frame_filename = os.path.join(save_dir, f'but_detecte_{frame_count}.jpg')\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frame_count += 1\n",
    "\n",
    "    # Dessiner les rectangles pour la cage et le ballon\n",
    "    if cage_coords:\n",
    "        cv2.rectangle(frame, (cage_coords[0], cage_coords[1]), (cage_coords[2], cage_coords[3]), (255, 0, 0), 2)\n",
    "    if ballon_coords:\n",
    "        cv2.rectangle(frame, (ballon_coords[0], ballon_coords[1]), (ballon_coords[2], ballon_coords[3]), (0, 0, 255), 2)\n",
    "\n",
    "    # Afficher les résultats sur l'image\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Écrire le frame annoté dans la vidéo de sortie\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "    # Afficher la frame annotée\n",
    "    cv2.imshow('Détection', annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libérer les ressources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
